{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1422d5f4-f9f4-4f9d-b547-0b438c7366d4",
   "metadata": {},
   "source": [
    "# Vorbereitung Google Dev Board\n",
    "\n",
    "Lesen und Folgen Sie Kapitel 3-4 des folgenden Links:\\n",
    "\n",
    "https://coral.ai/docs/dev-board/get-started/#install-mdt\n",
    "\n",
    "Wenn Sie sich mit ihrem Board verbunden haben, können Sie mit dem alias \"coral\"\\\n",
    "die vordefinierte Python-umgebung aktivieren.\\\n",
    "Mit:\n",
    "\n",
    "    jupyter-lab --ip=xxx.xxx.xxx.xxx\n",
    "    \n",
    "Können Sie jupyter-lab starten. Die Ip-adresse bekommen Sie mittels \"ip a\" heraus.\n",
    "Nun sollten Sie einen Link in der Kommandozeile finden, den Sie auf ihrem lokalen Rechner\n",
    "in den Browser eingeben können. \n",
    "\n",
    "\n",
    "# Quantisierung\n",
    "\n",
    "Bevor wir ein Netzwerk auf dem Dev-Board ausfuehren koennen muessen wir Besonderheiten beachten. \\\n",
    "Die Edge-TPU kann nur quantisierte Netzwerke ausfuehren. \\\n",
    "Wenn Sie ein NN auf ihrem lokalen Rechner trainieren, sind dessen Gewichte typischerweise im float32 format.\\\n",
    "Das Dev-Board verlangt Gewichte im uint8 format. Hier muss also eine Quantisierung von 32 bit auf 8 bit stattfinden. \\\n",
    "Sie Muessen ihr Netzwerk also quantisieren. \n",
    "Hierbei gibt es zwei Optionen:\n",
    "\n",
    "1. Quantization-aware training Trainingsschichten werden mittels ”fake” quantization nodes auf die 8-bit Gewichte der spaeteren Quantisierung vorbereitet.\n",
    "Daraus resultiert im allgemeinen eine hoehere Genauigkeit im Vergleich zum\n",
    "post-training.\n",
    "\n",
    "2. Full integer post-training quantization Jedes beliebige NN kann nach dem\n",
    "training quantisiert werden. Es wird allerdings eine \"helperfunktion\" benoetig,\n",
    "die der Quantisierungsroutine einen Beispielinput übergibt.\n",
    "\n",
    "Wir verwenden hier Variante 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24e71c5-1c2e-4360-a496-7cba55f0474a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Laden des Models!\n",
    "\n",
    "Modelname = \"Cnn\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(Modelname)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b233f6-3f7d-43ed-9b61-b0bad4f2dbcc",
   "metadata": {},
   "source": [
    " \n",
    " Wir benötigen nur ein paar Beispieldaten für die Quantisierung\\\n",
    " Hierbei wird der Prozess des Vorhersagens ein paar mal durchgespielt \\\n",
    " und die Gewichte demensprechend beschnitten\\\n",
    " Am Ende erhalten wir ein Model, das Gewichte im uint8 Format besitzt\\\n",
    " Vorteil hierbei ist, dass die Vorhersage schneller abgewickelt wird (Auf Kosten der Genauigkeit)\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27467fe4-f32e-4943-bd2c-ba615f851b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpiffitogi/assets\n"
     ]
    }
   ],
   "source": [
    "# Quantisierung\n",
    "\n",
    "modelname_quant = \"model_quant.tflite\"\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "X_train=x_train[0:100] / 255\n",
    "X_train=np.reshape(X_train, (X_train.shape[0],1,28,28,1))\n",
    "del x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def representative_data_gen_CNN():\n",
    "    for (label,img) in enumerate(X_train):     \n",
    "        yield [img.astype(np.float32)]\n",
    "\n",
    "\n",
    "# Kompiliertes und trainiertes Modell uebergeben\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "\n",
    "# Quantisierung aktivieren\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "\n",
    "# Hier den Generator einbinden\n",
    "converter.representative_dataset = representative_data_gen_CNN\n",
    "\n",
    "\n",
    "# Wirf Fehlermeldung, falls Operation nicht convertiert werden kann\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "\n",
    "# Quantisierung auf int8 setzen\n",
    "converter.target_spec.supported_types = [tf.int8]\n",
    "\n",
    "\n",
    "# Input/Output auf uint8\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "\n",
    "# Konvertieren\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "# Speichern\n",
    "with open(modelname_quant, 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c3b6e4-2b0d-496c-b96e-38ad9241c234",
   "metadata": {},
   "source": [
    "Für die Edge-TPU reicht dies allerdings noch nicht.\\\n",
    "Das Netzwerk muss erst noch durch den TPU-Compiler übersetzte werden.\n",
    "Auf einem Debian-basierten OS kann dieser mittels folgender Befehle installiert werden:\n",
    "\n",
    "---\n",
    "\n",
    "    curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
    "\n",
    "    echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" |\n",
    "    sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
    "\n",
    "    sudo apt-get update\n",
    "\n",
    "    sudo apt-get install edgetpu-compiler\n",
    "\n",
    "\n",
    "Ausführen:\n",
    "\n",
    "    edgetpu-compiler modelname.tflite\n",
    "\n",
    "---\n",
    "\n",
    "Alternativ kann ein Dockerimage dazu verwendet werden:\n",
    "\n",
    "---\n",
    "\n",
    "Im Notebook:\n",
    "\n",
    "    run_inside_docker = \"\\\"cd data && edgetpu_compiler {modelname}\\\"\"\\\n",
    "    .format(modelname = modelname_quant)\n",
    "\n",
    "    !docker run -v $(pwd):/data -it sichrist/edge_tpu_compiler bash -c \\\n",
    "        {run_inside_docker}\n",
    "    \n",
    "---\n",
    "\n",
    "Das Modell kann innerhalb des Notebooks mit folgendem Befehl auf das Board gepusht werden:\n",
    "\n",
    "    !mdt push {modelname_to_push} Pfad/zum/Verzeichnis/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
